# Morning Tasks — 2026-02-11

## Task 1: Genpelli MCP Server
Priority: P1
Estimate: 4h
Repo: ~/.openclaw/workspace/github/content_ai_generation
Files to create/modify:
- `mcp_server/__init__.py`
- `mcp_server/__main__.py`
- `mcp_server/server.py`
- `mcp_server/tools.py`
- `README.md` (add MCP section)

### What to Build
An MCP server that wraps Genpelli's video→clips pipeline as callable tools. Follow the same pattern as the Social Media Auto MCP server (JSON-RPC over stdio, `mcp` library). Expose the core capabilities: ingest video, list clips, get clip metadata, export clip.

### Technical Details
- Use `mcp` Python library (same as social-media-auto)
- Tools to expose:
  1. `ingest_video` — accepts video path/URL, runs ingestion pipeline, returns job ID
  2. `list_clips` — returns available clips with metadata (timestamps, topics, scores)
  3. `get_clip` — returns a specific clip's details and file path
  4. `generate_thumbnails` — creates thumbnails for a clip
- Import from existing `src.ingestion`, `src.assembly`, `src.analytics` modules
- Stdio transport for agent integration
- Load `.env` from repo root

### Acceptance Criteria
- [ ] `python -m mcp_server` starts without errors
- [ ] All 4 tools listed via MCP list_tools
- [ ] ingest_video tool calls existing pipeline code
- [ ] Follows same code structure as social-media-auto MCP server
- [ ] Code committed and pushed to git
- [ ] Logged to fruco-activities

---

## Task 2: Connect Genpelli → Social Media Auto
Priority: P1
Estimate: 4h
Repo: ~/.openclaw/workspace/github/holus
Files to create/modify:
- `holus/pipelines/__init__.py`
- `holus/pipelines/content_to_social.py`
- `holus/pipelines/README.md`

### What to Build
A pipeline module in Holus that orchestrates the flow: Genpelli produces clips → clips get enhanced text via Social Media Auto → posts are scheduled. This is the first cross-product integration — the Manager agent will use this pipeline to automate content creation end-to-end.

### Technical Details
- Pipeline class `ContentToSocialPipeline` with methods:
  1. `run(video_path, platforms)` — full pipeline
  2. `prepare_posts(clips)` — takes clips, generates captions via social-media-auto enhance_text
  3. `schedule_posts(posts, schedule)` — queues posts via social-media-auto post_to_platform
- Uses MCP client to call both Genpelli and Social Media Auto servers
- Config: which platforms, posting schedule, enhancement style
- Returns structured results (what was posted where, status)

### Acceptance Criteria
- [ ] Pipeline class importable from `holus.pipelines`
- [ ] `run()` method chains Genpelli → Social Media Auto
- [ ] Handles errors gracefully (clip fails → skip, don't crash)
- [ ] Unit tests with mocked MCP calls
- [ ] Code committed and pushed to git
- [ ] Logged to fruco-activities

---

## Task 3: Reachout — "Research Person" Feature
Priority: P1
Estimate: 6h
Repo: ~/.openclaw/workspace/github/reachout
Files to create/modify:
- `lib/research.js` (new)
- `api-server.js` (add routes)
- `public/research.html` or integrate into existing UI
- `specs/research-person.md`

### What to Build
A feature that takes a person's name + company and returns a research dossier: LinkedIn summary, recent posts/articles, mutual connections, talking points for outreach. This is the killer feature that makes Reachout useful for Juan's networking.

### Technical Details
- New API endpoint: `POST /api/research` — accepts `{name, company, context?}`
- Uses web search (Brave API via fetch) to find public info
- Structures results into: bio, role, interests, recent activity, suggested talking points
- LLM call (OpenAI or Anthropic) to synthesize research into actionable outreach brief
- Store research results in SQLite alongside contact record
- Frontend: simple form + results display

### Acceptance Criteria
- [ ] `POST /api/research` returns structured person dossier
- [ ] Web search finds relevant public information
- [ ] LLM synthesizes into talking points
- [ ] Results saved to database
- [ ] Code committed and pushed to git
- [ ] Logged to fruco-activities
